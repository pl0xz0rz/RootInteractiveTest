{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchamark bootstrap summary\n",
    "We should check invariants and make alarms in case of non probable fit values\n",
    "Normal fit with init weigths  - All params,  and errors  + true value + corresponding plots \n",
    "\n",
    "## Tests:\n",
    "* timing\n",
    "* precision and error estimates:\n",
    "  * Test 1.) - average of  N  <fits-true>  with weight one  - expected value is 0    \n",
    "    * error of <fits-true> ~ rmsexp/sqrt(N)\n",
    "  * Test 2.) RMS of N <fits-true>  with with weight one  - expected value covariance estimate  \n",
    "  * Test 3.) Pulls <fit-true>/rmsexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input tables and define derived variables:\n",
    "* delta\n",
    "* pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"benchmark_linear_bootstrap.pkl\")\n",
    "#df1=df1.query(\"number_points==1000\")\n",
    "df1[\"delta_0\"] = df1[\"params_true_0\"] - df1[\"params_0\"]\n",
    "df1[\"delta_1\"] = df1[\"params_true_1\"] - df1[\"params_1\"]\n",
    "df1[\"pull_0\"] = df1[\"delta_0\"] / df1[\"errors_0\"]\n",
    "df1[\"pull_1\"] = df1[\"delta_1\"] / df1[\"errors_1\"]\n",
    "#\n",
    "df1_tf = df1.query(\"fitter_name=='Tensorflow_BFGS'\")\n",
    "df1_scipy= df1.query(\"fitter_name=='Scipy_LM'\")\n",
    "df1_torch= df1.query(\"fitter_name=='Pytorch_LBFGS'\")\n",
    "N = len(df1_tf.index)\n",
    "display(df1.head(2))\n",
    "display(df1_tf.head(2))\n",
    "display(df1_scipy.head(2))\n",
    "display(df1_torch.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.) - average of  N  <fits-true>  with weight one  - expected value is 0    \n",
    "* error of <fits-true>:  $\\sigma_{N} = \\frac{\\sigma_{exp1}}{\\sqrt{N}}$\n",
    "* Alarm value $|<delta_{i}>| > 3 \\sigma_{N}$     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit type:\\tmean\\t\\trms_estimate\\t\\tstatus\")\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_tf[\"delta_0\"].mean(), df1_tf[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_tf[\"delta_0\"].mean())< 3* df1_tf[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Scipy:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_scipy[\"delta_0\"].mean(), df1_scipy[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_scipy[\"delta_0\"].mean())< 3* df1_scipy[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Pytorch:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_torch[\"delta_0\"].mean(), df1_torch[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_torch[\"delta_0\"].mean())< 3* df1_torch[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_tf[\"delta_1\"].mean(), df1_tf[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_tf[\"delta_1\"].mean())< 3* df1_tf[\"errors_1\"].mean()/np.sqrt(N)))\n",
    "print(\"Scipyi:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_scipy[\"delta_1\"].mean(), df1_scipy[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_scipy[\"delta_1\"].mean())< 3* df1_scipy[\"errors_1\"].mean()/np.sqrt(N)))\n",
    "print(\"Pytorch:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_torch[\"delta_1\"].mean(), df1_torch[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_torch[\"delta_1\"].mean())< 3* df1_torch[\"errors_1\"].mean()/np.sqrt(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1_scipy.query(\"number_points==1000\")[\"errors_1\"].mean(),\n",
    "df1_scipy.query(\"number_points==10000\")[\"errors_1\"].mean())\n",
    "print(df1_torch.query(\"number_points==1000\")[\"errors_1\"].mean()/np.sqrt(1000./2.),\n",
    "df1_torch.query(\"number_points==10000\")[\"errors_1\"].mean()/np.sqrt(10000./2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.) - RMS of N <fits-true>  with with weight one  - expected value covariance estimate \n",
    "* $\\sigma_{<rms_e>} \\approx \\frac{<rms_e>}{N}$\n",
    "* Alarm value $|std-<rms_e>| > 3 \\sigma_{N}$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit type:\\tstd\\t\\tbootstrap_std\\t\\trms_estimate\\t status\")\n",
    "isOK=np.abs(df1_tf[\"delta_0\"].std()-df1_tf[\"errors_0\"].mean())<3*np.sqrt((df1_tf[\"errors_0\"]**2).mean()/N)\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_tf[\"delta_0\"].std(),df1_tf[\"bs_std_0\"].mean(), df1_tf[\"errors_0\"].mean(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_scipy[\"delta_0\"].std()-df1_scipy[\"errors_0\"].mean())<3*df1_scipy[\"errors_0\"].mean()/np.sqrt(N)\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_scipy[\"delta_0\"].std(),df1_scipy[\"bs_std_0\"].mean(), df1_scipy[\"errors_0\"].mean(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_torch[\"delta_0\"].std()-df1_torch[\"errors_0\"].mean())<3*df1_torch[\"errors_0\"].mean()/np.sqrt(N)\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_torch[\"delta_0\"].std(),df1_torch[\"bs_std_0\"].mean(), df1_torch[\"errors_0\"].mean(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_tf[\"delta_1\"].std()-df1_tf[\"errors_1\"].mean())<3*df1_tf[\"errors_1\"].mean()/np.sqrt(N)\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_tf[\"delta_1\"].std(),df1_tf[\"bs_std_1\"].mean(), df1_tf[\"errors_1\"].mean(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_scipy[\"delta_1\"].std()-df1_scipy[\"errors_1\"].mean())<3*df1_scipy[\"errors_1\"].mean()/np.sqrt(N)\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_scipy[\"delta_1\"].std(),df1_scipy[\"bs_std_1\"].mean(), df1_scipy[\"errors_1\"].mean(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_torch[\"delta_1\"].std()-df1_torch[\"errors_1\"].mean())<3*df1_torch[\"errors_1\"].mean()/np.sqrt(N)\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t\\t%8.6F\\t%2.0F\" % (df1_torch[\"delta_1\"].std(),df1_torch[\"bs_std_1\"].mean(), df1_torch[\"errors_1\"].mean(),isOK))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3. - pulls of N with unit weights\n",
    "- Expected value 0\n",
    "- Alarm value $ |<pulls_i>|> \\frac{3}{\\sqrt{N}}$ or $ |std({pulls})-1|> \\frac{3}{\\sqrt{N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit type:\\tpull mean\\tpull std\\tstatus\")\n",
    "isOK=np.abs(df1_tf[\"pull_0\"].mean())<3/np.sqrt(N) and np.abs(df1_tf[\"pull_0\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_tf[\"pull_0\"].mean(),df1_tf[\"pull_0\"].std(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_scipy[\"pull_0\"].mean())<3/np.sqrt(N) and np.abs(df1_scipy[\"pull_0\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_scipy[\"pull_0\"].mean(),df1_scipy[\"pull_0\"].std(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_torch[\"pull_0\"].mean())<3/np.sqrt(N) and np.abs(df1_torch[\"pull_0\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_torch[\"pull_0\"].mean(),df1_torch[\"pull_0\"].std(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_tf[\"pull_1\"].mean())<3/np.sqrt(N) and np.abs(df1_tf[\"pull_1\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_tf[\"pull_1\"].mean(),df1_tf[\"pull_1\"].std(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_scipy[\"pull_1\"].mean())<3/np.sqrt(N) and np.abs(df1_scipy[\"pull_1\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_scipy[\"pull_1\"].mean(),df1_scipy[\"pull_1\"].std(),isOK))\n",
    "\n",
    "isOK=np.abs(df1_torch[\"pull_1\"].mean())<3/np.sqrt(N) and np.abs(df1_torch[\"pull_1\"].std()-1)<3/np.sqrt(N)\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t%2.0F\" % (df1_torch[\"pull_1\"].mean(),df1_torch[\"pull_1\"].std(),isOK))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1_tf[\"pull_0\"].hist())\n",
    "display(df1_scipy[\"pull_0\"].hist())\n",
    "display(df1_torch[\"pull_0\"].hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_torch[\"pull_0\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems suspicious, pytorch fitter seems to overestimate the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_torch.query(\"number_points==10000\")[\"time\"].hist()\n",
    "df1_scipy.query(\"number_points==10000\")[\"time\"].hist()\n",
    "df1_tf.query(\"number_points==10000\")[\"time\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(\"benchmark_linear_eachfit.pkl\")\n",
    "df2.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
