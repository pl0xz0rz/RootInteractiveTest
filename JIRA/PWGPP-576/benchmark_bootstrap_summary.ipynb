{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchamark bootstrap summary\n",
    "We should check invariants and make alarms in case of non probable fit values\n",
    "Normal fit with init weigths  - All params,  and errors  + true value + corresponding plots \n",
    "\n",
    "## Tests:\n",
    "* timing\n",
    "* precision and error estimates:\n",
    "  * Test - average of  N  <fits-true>  with weight one  - expected value is 0    \n",
    "    * error of <fits-true> ~ rmsexp/sqrt(N)\n",
    "  * RMS of N <fits-true>  with with weight one  - expected value covariance estimate  \n",
    "  * Pulls <fit-true>/rmsexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input tables and define derived variables:\n",
    "* delta\n",
    "* pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"benchmark_linear_bootstrap.pkl\")\n",
    "#df1=df1.query(\"number_points==1000\")\n",
    "df1[\"delta_0\"] = df1[\"params_true_0\"] - df1[\"params_0\"]\n",
    "df1[\"delta_1\"] = df1[\"params_true_1\"] - df1[\"params_1\"]\n",
    "df1[\"pull_0\"] = df1[\"delta_0\"] / df1[\"errors_0\"]\n",
    "df1[\"pull_1\"] = df1[\"delta_1\"] / df1[\"errors_1\"]\n",
    "#\n",
    "df1_tf = df1.query(\"fitter_name=='Tensorflow_BFGS'\")\n",
    "df1_scipy= df1.query(\"fitter_name=='Scipy_LM'\")\n",
    "df1_torch= df1.query(\"fitter_name=='Pytorch_LBFGS'\")\n",
    "N = len(df1_tf.index)\n",
    "display(df1.head(2))\n",
    "display(df1_tf.head(2))\n",
    "display(df1_scipy.head(2))\n",
    "display(df1_torch.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - average of  N  <fits-true>  with weight one  - expected value is 0    \n",
    "* error of <fits-true>:  $\\sigma_{N} = \\frac{\\sigma_{exp1}}{\\sqrt{N}}$\n",
    "* Alarm value $|<delta_{i}>| > 3 \\sigma_{N}$     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit type:\\tmean\\t\\trms_estimate\\t\\tstatus\")\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_tf[\"delta_0\"].mean(), df1_tf[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_tf[\"delta_0\"].mean())< 3* df1_tf[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Scipy:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_scipy[\"delta_0\"].mean(), df1_scipy[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_scipy[\"delta_0\"].mean())< 3* df1_scipy[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Pytorch:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_torch[\"delta_0\"].mean(), df1_torch[\"errors_0\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_torch[\"delta_0\"].mean())< 3* df1_torch[\"errors_0\"].mean()/np.sqrt(N)))\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_tf[\"delta_1\"].mean(), df1_tf[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_tf[\"delta_1\"].mean())< 3* df1_tf[\"errors_1\"].mean()/np.sqrt(N)))\n",
    "print(\"Scipyi:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_scipy[\"delta_1\"].mean(), df1_scipy[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_scipy[\"delta_1\"].mean())< 3* df1_scipy[\"errors_1\"].mean()/np.sqrt(N)))\n",
    "print(\"Pytorch:      \\t%8.6F\\t%8.6F\\t%8.0F\" % (df1_torch[\"delta_1\"].mean(), df1_torch[\"errors_1\"].mean()/np.sqrt(N), \\\n",
    "      np.abs(df1_torch[\"delta_1\"].mean())< 3* df1_torch[\"errors_1\"].mean()/np.sqrt(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1_scipy.query(\"number_points==1000\")[\"errors_1\"].mean(),\n",
    "df1_scipy.query(\"number_points==10000\")[\"errors_1\"].mean())\n",
    "print(df1_torch.query(\"number_points==1000\")[\"errors_1\"].mean()/np.sqrt(1000./2.),\n",
    "df1_torch.query(\"number_points==10000\")[\"errors_1\"].mean()/np.sqrt(10000./2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - RMS of N <fits-true>  with with weight one  - expected value covariance estimate  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit type:\\tstd\\t\\tbootstrap_std\\t\\trms_estimate\")\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_tf[\"delta_0\"].std(),df1_tf[\"bs_std_0\"].mean(), df1_tf[\"errors_0\"].mean()))\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_scipy[\"delta_0\"].std(),df1_scipy[\"bs_std_0\"].mean(), df1_scipy[\"errors_0\"].mean()))\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_torch[\"delta_0\"].std(),df1_torch[\"bs_std_0\"].mean(), df1_torch[\"errors_0\"].mean()))\n",
    "print(\"Tensorflow:\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_tf[\"delta_1\"].std(),df1_tf[\"bs_std_1\"].mean(), df1_tf[\"errors_1\"].mean()))\n",
    "print(\"Scipy:\\t\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_scipy[\"delta_1\"].std(),df1_scipy[\"bs_std_1\"].mean(), df1_scipy[\"errors_1\"].mean()))\n",
    "print(\"Pytorch:\\t%8.6F\\t%8.6F\\t\\t%8.6F\" % (df1_torch[\"delta_1\"].std(),df1_torch[\"bs_std_1\"].mean(), df1_torch[\"errors_1\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tf[\"pull_0\"].hist()\n",
    "df1_scipy[\"pull_0\"].hist()\n",
    "df1_torch[\"pull_0\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_torch[\"pull_0\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems suspicious, pytorch fitter seems to overestimate the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_torch.query(\"number_points==10000\")[\"time\"].hist()\n",
    "df1_scipy.query(\"number_points==10000\")[\"time\"].hist()\n",
    "df1_tf.query(\"number_points==10000\")[\"time\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(\"benchmark_linear_eachfit.pkl\")\n",
    "df2.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
